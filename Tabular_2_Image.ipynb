{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af028bf3",
   "metadata": {},
   "source": [
    "## Bi-Weekly 3\n",
    "### Brian Cain\n",
    "#### Tabular_2_Image.ipynb\n",
    "\n",
    "This past week Dr. Raissi mentioned during one lecture that Convolutional Nueral Networks are so useful because they are extremely smart and can fit small datasets in a way that results in high accuracy and good generalization. However, once datasets become massive other strategies like transformers work better for datasets like ImageNet.\n",
    "\n",
    "This motivated me to explore the possibility of transforming a small tabular dataset into an image dataset and seeing if the results are better in a convolutional neural network than they are in another standard ML Model. Below I have described the setup. \n",
    "\n",
    "<b>Set-up:</b> \n",
    "* This summer I did some data wrangling on historical college football game outcomes and made a predictive Random Forest model that predicts the winner of a game at an accuracy rate of 67%\n",
    "* In this experiment, I will load the data and manipulate it such that it takes the form of image data rather than tabular data\n",
    "* In addition to this, I will apply some concepts covered in the \"Small Networks\" module like pruning in order to see if the accuracy can even be further enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d5fed9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameId</th>\n",
       "      <th>school</th>\n",
       "      <th>week_num</th>\n",
       "      <th>season</th>\n",
       "      <th>homeBool</th>\n",
       "      <th>talent_points_avg</th>\n",
       "      <th>talent_rank_avg</th>\n",
       "      <th>win</th>\n",
       "      <th>rush_td_movAvg</th>\n",
       "      <th>pass_td_movAvg</th>\n",
       "      <th>...</th>\n",
       "      <th>opp_points_Q4_movAvg</th>\n",
       "      <th>opp_talent_points_avg_movAvg</th>\n",
       "      <th>opp_talent_rank_avg_movAvg</th>\n",
       "      <th>diff_points_movAvg</th>\n",
       "      <th>diff_rush_yards_movAvg</th>\n",
       "      <th>diff_pass_yards_movAvg</th>\n",
       "      <th>diff_total_yards_movAvg</th>\n",
       "      <th>diff_turnovers_movAvg</th>\n",
       "      <th>games_played</th>\n",
       "      <th>games_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400548194</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>109.153333</td>\n",
       "      <td>90.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>134.774444</td>\n",
       "      <td>82.555556</td>\n",
       "      <td>-10.333333</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-69.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400548267</td>\n",
       "      <td>Washington State</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>165.193333</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>127.826667</td>\n",
       "      <td>82.444444</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>-134.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400548198</td>\n",
       "      <td>Oregon State</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>186.023333</td>\n",
       "      <td>43.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>82.251667</td>\n",
       "      <td>114.264340</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>54.500000</td>\n",
       "      <td>154.500000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400548195</td>\n",
       "      <td>Fresno State</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>99.893333</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>229.554444</td>\n",
       "      <td>24.111111</td>\n",
       "      <td>-35.666667</td>\n",
       "      <td>-166.000000</td>\n",
       "      <td>-96.666667</td>\n",
       "      <td>-262.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400548266</td>\n",
       "      <td>California</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>219.476667</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>118.448333</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>169.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>400548197</td>\n",
       "      <td>New Mexico State</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>80.880000</td>\n",
       "      <td>109.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>74.917778</td>\n",
       "      <td>127.611111</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-94.666667</td>\n",
       "      <td>102.666667</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400560174</td>\n",
       "      <td>Houston</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>160.453333</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>93.412222</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400547789</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>226.696667</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>95.338889</td>\n",
       "      <td>104.801418</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>104.666667</td>\n",
       "      <td>299.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>400547742</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>253.693333</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>174.620000</td>\n",
       "      <td>67.166667</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>261.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>400548414</td>\n",
       "      <td>Georgia Southern</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>33.045000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>138.945556</td>\n",
       "      <td>79.555556</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>161.666667</td>\n",
       "      <td>-43.333333</td>\n",
       "      <td>118.333333</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gameId            school  week_num  season  homeBool  talent_points_avg  \\\n",
       "0  400548194         Louisiana         4    2014         1         109.153333   \n",
       "1  400548267  Washington State         4    2014         1         165.193333   \n",
       "2  400548198      Oregon State         4    2014         1         186.023333   \n",
       "3  400548195      Fresno State         4    2014         1          99.893333   \n",
       "4  400548266        California         4    2014         1         219.476667   \n",
       "5  400548197  New Mexico State         4    2014         1          80.880000   \n",
       "6  400560174           Houston         4    2014         1         160.453333   \n",
       "7  400547789          Nebraska         4    2014         1         226.696667   \n",
       "8  400547742           Clemson         4    2014         1         253.693333   \n",
       "9  400548414  Georgia Southern         4    2014         1          33.045000   \n",
       "\n",
       "   talent_rank_avg  win  rush_td_movAvg  pass_td_movAvg  ...  \\\n",
       "0        90.333333  0.0        1.333333        2.000000  ...   \n",
       "1        58.666667  0.0        0.333333        4.333333  ...   \n",
       "2        43.666667  1.0        1.500000        2.000000  ...   \n",
       "3        96.000000  1.0        1.333333        1.333333  ...   \n",
       "4        28.666667  0.0        1.500000        4.000000  ...   \n",
       "5       109.666667  0.0        1.000000        2.333333  ...   \n",
       "6        62.000000  1.0        1.333333        1.333333  ...   \n",
       "7        23.333333  1.0        3.000000        2.666667  ...   \n",
       "8        15.000000  0.0        3.000000        2.500000  ...   \n",
       "9       133.000000  1.0        5.000000        1.333333  ...   \n",
       "\n",
       "   opp_points_Q4_movAvg  opp_talent_points_avg_movAvg  \\\n",
       "0              8.000000                    134.774444   \n",
       "1              9.000000                    127.826667   \n",
       "2             11.500000                     82.251667   \n",
       "3              9.333333                    229.554444   \n",
       "4              1.500000                    118.448333   \n",
       "5              9.333333                     74.917778   \n",
       "6              3.333333                     93.412222   \n",
       "7              2.333333                     95.338889   \n",
       "8             10.500000                    174.620000   \n",
       "9              7.000000                    138.945556   \n",
       "\n",
       "   opp_talent_rank_avg_movAvg  diff_points_movAvg  diff_rush_yards_movAvg  \\\n",
       "0                   82.555556          -10.333333               30.000000   \n",
       "1                   82.444444           10.333333             -134.000000   \n",
       "2                  114.264340           11.500000               54.500000   \n",
       "3                   24.111111          -35.666667             -166.000000   \n",
       "4                   89.333333           24.000000               71.500000   \n",
       "5                  127.611111            2.000000              -94.666667   \n",
       "6                  104.000000            6.333333              -90.000000   \n",
       "7                  104.801418           33.666667              195.000000   \n",
       "8                   67.166667           24.500000               10.500000   \n",
       "9                   79.555556           23.666667              161.666667   \n",
       "\n",
       "   diff_pass_yards_movAvg  diff_total_yards_movAvg  diff_turnovers_movAvg  \\\n",
       "0              -69.000000               -39.000000               2.666667   \n",
       "1              297.000000               163.000000               1.000000   \n",
       "2              154.500000               209.000000              -2.000000   \n",
       "3              -96.666667              -262.666667               0.666667   \n",
       "4               98.000000               169.500000              -0.500000   \n",
       "5              102.666667                 8.000000              -0.333333   \n",
       "6               85.000000                -5.000000              -0.666667   \n",
       "7              104.666667               299.666667               0.333333   \n",
       "8              251.000000               261.500000               0.000000   \n",
       "9              -43.333333               118.333333              -0.666667   \n",
       "\n",
       "   games_played  games_won  \n",
       "0           3.0        1.0  \n",
       "1           3.0        1.0  \n",
       "2           2.0        2.0  \n",
       "3           3.0        0.0  \n",
       "4           2.0        2.0  \n",
       "5           3.0        2.0  \n",
       "6           3.0        1.0  \n",
       "7           3.0        3.0  \n",
       "8           2.0        1.0  \n",
       "9           3.0        1.0  \n",
       "\n",
       "[10 rows x 46 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##Pull in the data\n",
    "##Import the aggregated dataset and display\n",
    "gameRecords = pd.read_csv('D:\\College_Football_Model_Data\\\\gameRecords_df.csv')\n",
    "gameRecords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd96906",
   "metadata": {},
   "source": [
    "In the output above it can be seen that there is a table with unique Game Id's for every game player from the 2013-2019 season. Each game ID appears twice in the dataset, appearing the first time for the home teams data and a second time for the away teams data. Together, gameID and school make a primary key. Additionally in this dataset are a variety of aggregated average stats for each team that season, including how much recruiting talent they have, their average offensive yards, winning percentage, and more. \n",
    "\n",
    "Note: 2020 was omitted during my summer work because it was a weird year with statistics in football as a result of covid.\n",
    "\n",
    "This dataset is great, but it must condense each game into a single observation, which leads us to viewing another dataset that I created this summer which I will pull in now, but the above dataset gives a general idea of where the next dataset comes from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5e7e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gameId</th>\n",
       "      <th>school</th>\n",
       "      <th>week_num</th>\n",
       "      <th>season</th>\n",
       "      <th>homeBool</th>\n",
       "      <th>win</th>\n",
       "      <th>games_played</th>\n",
       "      <th>games_won</th>\n",
       "      <th>quickStart</th>\n",
       "      <th>...</th>\n",
       "      <th>net_diff_turnovers_movAvg</th>\n",
       "      <th>net_winPct</th>\n",
       "      <th>net_off_field_pos_eff</th>\n",
       "      <th>off_rush_advantage</th>\n",
       "      <th>off_pass_advantage</th>\n",
       "      <th>def_rush_advantage</th>\n",
       "      <th>def_pass_advantage</th>\n",
       "      <th>scoring_advantage</th>\n",
       "      <th>win_margin_advantage</th>\n",
       "      <th>turnover_margin_advantage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>707</td>\n",
       "      <td>400787446</td>\n",
       "      <td>Liberty</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516971</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.748207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3080</td>\n",
       "      <td>401112126</td>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583551</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>3.239068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178</td>\n",
       "      <td>400548367</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548303</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-4.827132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2918</td>\n",
       "      <td>401012797</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529077</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>-3.017582</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2527</td>\n",
       "      <td>401015009</td>\n",
       "      <td>UAB</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595300</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.604865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     gameId      school  week_num  season  homeBool  win  \\\n",
       "0         707  400787446     Liberty         5    2015         1  1.0   \n",
       "1        3080  401112126  Texas Tech         6    2019         0  1.0   \n",
       "2         178  400548367    Kentucky         7    2014         1  1.0   \n",
       "3        2918  401012797      Oregon        13    2018         0  1.0   \n",
       "4        2527  401015009         UAB         6    2018         0  1.0   \n",
       "\n",
       "   games_played  games_won  quickStart  ...  net_diff_turnovers_movAvg  \\\n",
       "0           1.0        0.0           1  ...                   0.516971   \n",
       "1           4.0        2.0           0  ...                   0.583551   \n",
       "2           5.0        4.0           0  ...                   0.548303   \n",
       "3          10.0        7.0           0  ...                   0.529077   \n",
       "4           4.0        3.0           0  ...                   0.595300   \n",
       "\n",
       "   net_winPct  net_off_field_pos_eff  off_rush_advantage  off_pass_advantage  \\\n",
       "0    0.333333               4.748207                   0                   0   \n",
       "1    0.350000               3.239068                   0                   0   \n",
       "2    0.600000              -4.827132                   1                   1   \n",
       "3    0.759091              -3.017582                   1                   1   \n",
       "4    0.500000              -0.604865                   1                   0   \n",
       "\n",
       "   def_rush_advantage  def_pass_advantage  scoring_advantage  \\\n",
       "0                   1                   0                  0   \n",
       "1                   0                   1                  0   \n",
       "2                   0                   1                  1   \n",
       "3                   1                   1                  1   \n",
       "4                   0                   1                  1   \n",
       "\n",
       "   win_margin_advantage  turnover_margin_advantage  \n",
       "0                     0                          1  \n",
       "1                     0                          1  \n",
       "2                     1                          1  \n",
       "3                     1                          1  \n",
       "4                     1                          0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Clear old data from memory\n",
    "del gameRecords\n",
    "\n",
    "##Pull in new data\n",
    "data = pd.read_csv('D:\\College_Football_Model_Data\\Final_Pretrain_Data.csv',index_col=False)\n",
    "\n",
    "##Display the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a576e",
   "metadata": {},
   "source": [
    "With a quick glance, it can be observed that in previous steps I have already normalized the dataset using min-max normalization, and as well some \"advantage\" categorical features were added to each observation to try and grant a model more insight into which teams have certain offensive/defensive advantages. \n",
    "\n",
    "Let's explore what columns we have in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cf7fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in College Football Dataset:\n",
      "------------------------------------\n",
      "Unnamed: 0\n",
      "gameId\n",
      "school\n",
      "week_num\n",
      "season\n",
      "homeBool\n",
      "win\n",
      "games_played\n",
      "games_won\n",
      "quickStart\n",
      "opposition_homeBool\n",
      "opposition_win\n",
      "opposition_games_played\n",
      "opposition_games_won\n",
      "net_talent_points_avg\n",
      "net_talent_rank_avg\n",
      "net_rush_td_movAvg\n",
      "net_pass_td_movAvg\n",
      "net_rush_attempt_movAvg\n",
      "net_yp_rush_movAvg\n",
      "net_rush_yards_movAvg\n",
      "net_yp_pass_movAvg\n",
      "net_pass_yards_movAvg\n",
      "net_total_yards_movAvg\n",
      "net_turnovers_movAvg\n",
      "net_completion_pct_movAvg\n",
      "net_points_movAvg\n",
      "net_points_Q1_movAvg\n",
      "net_points_Q2_movAvg\n",
      "net_points_Q3_movAvg\n",
      "net_points_Q4_movAvg\n",
      "net_opp_rush_td_movAvg\n",
      "net_opp_pass_td_movAvg\n",
      "net_opp_yp_rush_movAvg\n",
      "net_opp_rush_yards_movAvg\n",
      "net_opp_yp_pass_movAvg\n",
      "net_opp_pass_yards_movAvg\n",
      "net_opp_total_yards_movAvg\n",
      "net_opp_turnovers_movAvg\n",
      "net_opp_completion_pct_movAvg\n",
      "net_opp_points_movAvg\n",
      "net_opp_points_Q1_movAvg\n",
      "net_opp_points_Q2_movAvg\n",
      "net_opp_points_Q3_movAvg\n",
      "net_opp_points_Q4_movAvg\n",
      "net_opp_talent_points_avg_movAvg\n",
      "net_opp_talent_rank_avg_movAvg\n",
      "net_diff_points_movAvg\n",
      "net_diff_rush_yards_movAvg\n",
      "net_diff_pass_yards_movAvg\n",
      "net_diff_total_yards_movAvg\n",
      "net_diff_turnovers_movAvg\n",
      "net_winPct\n",
      "net_off_field_pos_eff\n",
      "off_rush_advantage\n",
      "off_pass_advantage\n",
      "def_rush_advantage\n",
      "def_pass_advantage\n",
      "scoring_advantage\n",
      "win_margin_advantage\n",
      "turnover_margin_advantage\n"
     ]
    }
   ],
   "source": [
    "##Display columns that are present within the dataset\n",
    "print('Columns in College Football Dataset:')\n",
    "print('------------------------------------')\n",
    "for i in data.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bda37fe",
   "metadata": {},
   "source": [
    "In the columns listed above, you can notice there are a lot of columns that start with \"net\", these columns indicated the normalized net difference in the home and away teams average statistics for the season for each metric. \n",
    "\n",
    "We can also notice, that from a predictive standpoint, there are columns we don't need to include when changing each tabular observation into an image, these columns are gameId, school, week_num, season, and perhaps a few other \"garbage\" statistics that we might want to leave out. Also note that the win column are the labels, with 0 being a loss, and 1 being a win. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af033ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a list of columns that we would like to keep for prediction\n",
    "cols_to_keep = ['quickStart','net_talent_points_avg','net_talent_rank_avg','net_rush_td_movAvg',\n",
    "                'net_pass_td_movAvg','net_rush_attempt_movAvg','net_yp_rush_movAvg','net_rush_yards_movAvg',\n",
    "                'net_yp_pass_movAvg','net_pass_yards_movAvg','net_total_yards_movAvg','net_turnovers_movAvg',\n",
    "                'net_completion_pct_movAvg','net_points_movAvg','net_opp_rush_td_movAvg','net_opp_pass_td_movAvg',\n",
    "                'net_opp_yp_rush_movAvg','net_opp_rush_yards_movAvg','net_opp_yp_pass_movAvg',\n",
    "                'net_opp_pass_yards_movAvg','net_opp_total_yards_movAvg','net_opp_turnovers_movAvg',\n",
    "                'net_opp_completion_pct_movAvg','net_opp_points_movAvg','net_opp_points_Q1_movAvg',\n",
    "                'net_opp_points_Q2_movAvg','net_opp_points_Q3_movAvg','net_opp_points_Q4_movAvg',\n",
    "                'net_diff_points_movAvg','net_diff_rush_yards_movAvg','net_diff_pass_yards_movAvg',\n",
    "                'net_diff_total_yards_movAvg','net_diff_turnovers_movAvg','net_winPct','net_off_field_pos_eff',\n",
    "                'off_rush_advantage','off_pass_advantage','def_rush_advantage','def_pass_advantage',\n",
    "                'scoring_advantage','win_margin_advantage','turnover_margin_advantage']\n",
    "\n",
    "##Filter the dataset\n",
    "labelsData = data['win']\n",
    "data = data[cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2a78eb",
   "metadata": {},
   "source": [
    "Below I define a function to turn the data into image arrays and image labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3c19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now turn the dataframe into a list of lists\n",
    "data = data.values.tolist()\n",
    "labels = np.array(labelsData.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ddfb7",
   "metadata": {},
   "source": [
    "Create 8x6 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b50f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = 0\n",
    "for i in data:\n",
    "    data[ct] = np.reshape(i, (7,6))\n",
    "    ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89ebc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24cdd83d2c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANYAAAD4CAYAAACQRRhoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKUklEQVR4nO3d/6ued33H8eerJ1FrWqmyTromrG66gshmJYSNgLDOSdSi+8EfWlDYEMpgjhYF0R/9A1a6H8Yg1O4Ldg1iLYhzrQFbSsF+S021NXV0paNncUQJxSbCuqTv/XCuktP2tOfKPO/ruu+T5wMOOXfO3fN5h/R5rvu+ct/XJ1WFpK110dwDSNuRYUkNDEtqYFhSA8OSGuzo+KYrl+yqHe98V8e33tRbV0/Psi7A7/3+r2Zb+8cnL59t7QvVmZMnOXv6dDb6WktYO975Ln7rizd3fOtNvfcLD82yLsC99x6dbe3fPfSXs60NkAvwX23+65Zb3/BrPhSUGhiW1MCwpAaGJTUwLKmBYUkNDEtqYFhSA8OSGhiW1MCwpAajwkpyIMlPkzyT5MvdQ0nLbtOwkqwAfwd8DHg/cEOS93cPJi2zMUesfcAzVfVsVb0EHAI+1TuWtNzGhHUl8Py626vD771KkhuTPJbksbOn53tPlLQIxoS10Ru5Xvfum6o6WFV7q2rvyq5dv/5k0hIbE9YqsGfd7d3A8Z5xpO1hTFiPAu9L8p4kbwGuB77dO5a03DZ9a35VnUnyeeBeYAW4vaqeap9MWmKjrnlRVd8Fvts8i7Rt+MoLqYFhSQ0MS2pgWFIDw5IaGJbUwLCkBoYlNTAsqUHLbiMw3+4T//E3fzjPwsB775xv7Q33ktFsPGJJDQxLamBYUgPDkhoYltTAsKQGhiU1MCypgWFJDQxLamBYUgPDkhqM2W3k9iQnkjw5xUDSdjDmiPWPwIHmOaRtZdOwquoB4OQEs0jbxpY9x3IbH+mcLQvLbXykczwrKDUwLKnBmNPtdwI/AK5Osprkc/1jScttzP5YN0wxiLSd+FBQamBYUgPDkhoYltTAsKQGhiU1MCypgWFJDQxLatC2jU/NtK/MXNsHwXx/Zi0ej1hSA8OSGhiW1MCwpAaGJTUwLKmBYUkNDEtqYFhSA8OSGhiW1MCwpAZjriu4J8l9SY4leSrJTVMMJi2zMa9uPwN8saoeT3IpcCTJ4ar6SfNs0tIas43Pz6rq8eHzF4FjwJXdg0nL7LyeYyW5CrgGeHiDr7mNjzQYHVaSS4C7gJur6pev/brb+EjnjAoryU7Worqjqr7VO5K0/MacFQzwNeBYVd3SP5K0/MYcsfYDnwWuTXJ0+Ph481zSUhuzjc+DgJdJkc6Dr7yQGhiW1MCwpAaGJTUwLKmBYUkNDEtqYFhSA8OSGrRt43MhmnMLobm5hdGrecSSGhiW1MCwpAaGJTUwLKmBYUkNDEtqYFhSA8OSGhiW1MCwpAaGJTUYc8HOtyV5JMkTwzY+X51iMGmZjXl1+/8A11bVqeFS0w8m+beqeqh5NmlpjblgZwGnhps7h48L+A0S0ubGboqwkuQocAI4XFVu4yO9iVFhVdXZqvogsBvYl+QDG9zHbXykwXmdFayqF4D7gQMdw0jbxZizgpcnuWz4/GLgI8DTzXNJS23MWcErgH9KssJaiN+oqu/0jiUttzFnBX/E2r7DkkbylRdSA8OSGhiW1MCwpAaGJTUwLKmBYUkNDEtqYFhSA8OSGrTsj5WXYcfpeTZM+t/LXp5lXYDaOd/7P3e8sDLb2gDM+GdfRB6xpAaGJTUwLKmBYUkNDEtqYFhSA8OSGhiW1MCwpAaGJTUwLKnB6LCG67f/MInXFJQ2cT5HrJuAY12DSNvJ2N1GdgOfAG7rHUfaHsYesW4FvgS84Xsy3MZHOmfMpgjXASeq6sib3c9tfKRzxhyx9gOfTPIccAi4NsnXW6eSltymYVXVV6pqd1VdBVwPfL+qPtM+mbTE/HcsqcF5XfOiqu5nbUdHSW/CI5bUwLCkBoYlNTAsqYFhSQ0MS2pgWFIDw5IaGJbUwLCkBi3b+NRFcPbt82zrctFL82wfBMCMa8+5hRDA2Yvn2z5p5VeLd3xYvImkbcCwpAaGJTUwLKmBYUkNDEtqYFhSA8OSGhiW1MCwpAaGJTUY9VrB4Sq4LwJngTNVtbdzKGnZnc+LcP+4qn7RNom0jfhQUGowNqwCvpfkSJIbN7qD2/hI54x9KLi/qo4n+U3gcJKnq+qB9XeoqoPAQYC37tkz75uDpJmNOmJV1fHh1xPA3cC+zqGkZTdm47ldSS595XPgo8CT3YNJy2zMQ8F3A3cneeX+/1JV97ROJS25TcOqqmeBP5hgFmnb8HS71MCwpAaGJTUwLKmBYUkNDEtqYFhSA8OSGhiW1MCwpAYt2/gAa+/gmkHN+KMi8+1kM7s5t9KZ8+/8jSzgSNLyMyypgWFJDQxLamBYUgPDkhoYltTAsKQGhiU1MCypgWFJDUaFleSyJN9M8nSSY0n+qHswaZmNfRHu3wL3VNWnk7wFeHvjTNLS2zSsJO8APgz8OUBVvQS81DuWtNzGPBT8HeDnwD8k+WGS24ZruL+K2/hI54wJawfwIeDvq+oa4DTw5dfeqaoOVtXeqtq7sut13UkXlDFhrQKrVfXwcPubrIUm6Q1sGlZV/TfwfJKrh9/6E+AnrVNJS27sWcG/Bu4Yzgg+C/xF30jS8hsVVlUdBfb2jiJtH77yQmpgWFIDw5IaGJbUwLCkBoYlNTAsqYFhSQ0MS2pgWFKDVG39fjtJfg785//zP/8N4BdbOI5ru3bX2r9dVZdv9IWWsH4dSR6rqllel+jarr1VfCgoNTAsqcEihnXQtV172ddeuOdY0nawiEcsaekZltRgocJKciDJT5M8k+R1l1hrXPf2JCeSPDnVmuvW3pPkvuHS3U8luWnCtd+W5JEkTwxrf3WqtdfNsDJcr/I7E6/7XJIfJzma5LEt//6L8hwryQrw78CfsnbJtUeBG6qq/YpQST4MnAL+uao+0L3ea9a+Ariiqh5PcilwBPizif7cAXZV1akkO4EHgZuq6qHutdfN8AXWrqfyjqq6bsJ1nwP2VlXLP04v0hFrH/BMVT07XMb6EPCpKRauqgeAk1OstcHaP6uqx4fPXwSOAVdOtHZV1anh5s7hY7KftEl2A58AbptqzaksUlhXAs+vu73KRP+DLYokVwHXAA9vctetXHMlyVHgBHB43YVZp3Ar8CXg5QnXfEUB30tyJMmNW/3NFymsbPB7i/E4dQJJLgHuAm6uql9OtW5Vna2qDwK7gX1JJnkonOQ64ERVHZlivQ3sr6oPAR8D/mp4OrBlFimsVWDPutu7geMzzTKp4fnNXcAdVfWtOWaoqheA+4EDEy25H/jk8FznEHBtkq9PtDZVdXz49QRwN2tPRbbMIoX1KPC+JO8Zrrh7PfDtmWdqN5xA+BpwrKpumXjty5NcNnx+MfAR4Okp1q6qr1TV7qq6irW/6+9X1WemWDvJruFEEcPOOR8FtvSM8MKEVVVngM8D97L2BP4bVfXUFGsnuRP4AXB1ktUkn5ti3cF+4LOs/cQ+Onx8fKK1rwDuS/Ij1n6wHa6qSU97z+TdwINJngAeAf61qu7ZygUW5nS7tJ0szBFL2k4MS2pgWFIDw5IaGJbUwLCkBoYlNfg/IQKpbHZOigQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141d15a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[:2681]\n",
    "y_train = labels[:2681]\n",
    "x_test = data[2681:]\n",
    "y_test = labels[2681:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b970a139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2681, 7, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b428ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a validation set\n",
    "##Split training data so we have a validation set\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bb53b4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 7, 6, 32)          64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 64)          2112      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 128)         8320      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,625\n",
      "Trainable params: 10,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2010 samples, validate on 671 samples\n",
      "Epoch 1/200\n",
      "2010/2010 - 1s - loss: nan - acc: 0.3438 - val_loss: nan - val_acc: 0.3458\n",
      "Epoch 2/200\n",
      "2010/2010 - 1s - loss: nan - acc: 0.3294 - val_loss: nan - val_acc: 0.3458\n",
      "Epoch 3/200\n",
      "2010/2010 - 0s - loss: nan - acc: 0.3294 - val_loss: nan - val_acc: 0.3458\n",
      "Epoch 4/200\n",
      "2010/2010 - 0s - loss: nan - acc: 0.3294 - val_loss: nan - val_acc: 0.3458\n",
      "Epoch 5/200\n",
      "2010/2010 - 1s - loss: nan - acc: 0.3294 - val_loss: nan - val_acc: 0.3458\n",
      "Epoch 6/200\n",
      "2010/2010 - 1s - loss: nan - acc: 0.3294 - val_loss: nan - val_acc: 0.3458\n",
      "Epoch 7/200\n",
      "2010/2010 - 1s - loss: nan - acc: 0.3294 - val_loss: nan - val_acc: 0.3458\n",
      "Epoch 8/200\n",
      "2010/2010 - 1s - loss: nan - acc: 0.3294 - val_loss: nan - val_acc: 0.3458\n",
      "Epoch 9/200\n",
      "2010/2010 - 1s - loss: nan - acc: 0.3294 - val_loss: nan - val_acc: 0.3458\n",
      "Epoch 10/200\n",
      "2010/2010 - 1s - loss: nan - acc: 0.3294 - val_loss: nan - val_acc: 0.3458\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c3d181942974>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m##Fit our created model over 10 epochs (Batch size of 6,000)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mmodel2_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "##Create model\n",
    "model2 = tf.keras.models.Sequential()\n",
    "\n",
    "##Add a layer with 32 filters for a 1x1 convolution\n",
    "model2.add(tf.keras.layers.Conv2D(32, (1, 1), activation='relu', input_shape=(7,6,1))) ##Grayscale input shape\n",
    "model2.add(tf.keras.layers.MaxPooling2D((3, 3),padding='valid')) ##Perform a 3x3 max-pooling\n",
    "##Add a layer that generates 64 feature maps and max pools again with 3x3 \n",
    "model2.add(tf.keras.layers.Conv2D(64, (1, 1), activation='relu'))\n",
    "\n",
    "##Perform final convolution operations and conduct global average pooling with 128 feature maps\n",
    "model2.add(tf.keras.layers.Conv2D(128, (1, 1), activation='relu'))\n",
    "model2.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "##Add a single dense layer after global average pooling\n",
    "model2.add(tf.keras.layers.Dense(1, activation='softmax')) ##Must have 9 neurons\n",
    "\n",
    "##Check out the model architecture\n",
    "model2.summary()\n",
    "\n",
    "##Compile the model\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "##Fit our created model over 10 epochs (Batch size of 6,000)\n",
    "model2_fit = model2.fit(x_train, y_train, batch_size=24, epochs=200, validation_data=(x_val, y_val),verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32cf37",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "(mention something about making a more customized loss function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
